"""
Advanced GraphRAG Engine with Vector Embeddings and Relationship Mapping
ê³ ê¸‰ GraphRAG ì—”ì§„ - ë²¡í„° ì„ë² ë”©ê³¼ ê´€ê³„í˜• ê²€ìƒ‰ì˜ ìœµí•©
"""

import asyncio
import json
import numpy as np
from typing import List, Dict, Any, Optional, Tuple, Set
from datetime import datetime
import openai
from openai import AsyncOpenAI

# Database and existing modules
from water_app.db import q, execute_query
from water_app.queries.latest import latest_snapshot
from water_app.queries.qc import qc_rules


class GraphRAGEngine:
    """ê³ ê¸‰ GraphRAG ì—”ì§„ - ì§€ì‹ ê·¸ë˜í”„ì™€ ë²¡í„° ê²€ìƒ‰ì˜ ìœµí•©"""

    def __init__(self):
        self.openai_client = None
        self.embedding_model = "text-embedding-ada-002"
        self.embedding_cache = {}
        self.knowledge_graph = {}  # ì„¼ì„œ ê°„ ê´€ê³„ ê·¸ë˜í”„
        self.similarity_threshold = 0.75

    async def initialize(self):
        """GraphRAG ì—”ì§„ ì´ˆê¸°í™”"""
        # í™˜ê²½ë³€ìˆ˜ ëª…ì‹œì  ë¡œë“œ
        import os
        from dotenv import load_dotenv
        load_dotenv()

        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        from water_app.utils.secure_config import get_api_key_manager
        api_manager = get_api_key_manager()
        api_key = api_manager.get_openai_key()

        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì§ì ‘ í™•ì¸ë„ ì‹œë„
        if not api_key:
            api_key = os.getenv('OPENAI_API_KEY')
            print(f"ğŸ” í™˜ê²½ë³€ìˆ˜ì—ì„œ ì§ì ‘ ë¡œë“œ ì‹œë„: {'âœ… ì„±ê³µ' if api_key else 'âŒ ì‹¤íŒ¨'}")

        if api_key:
            self.openai_client = AsyncOpenAI(api_key=api_key)
            print("âœ… GraphRAG OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        else:
            print("âš ï¸ OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. ë²¡í„° ì„ë² ë”© ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.")

        # ì§€ì‹ ê·¸ë˜í”„ êµ¬ì¶•
        await self._build_knowledge_graph()

        # ì„ë² ë”© ì—…ë°ì´íŠ¸
        await self._update_embeddings()

        print("ğŸ•¸ï¸ GraphRAG ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")

    async def _build_knowledge_graph(self):
        """ì„¼ì„œ ê°„ ê´€ê³„ ê¸°ë°˜ ì§€ì‹ ê·¸ë˜í”„ êµ¬ì¶•"""
        print("ğŸ•¸ï¸ ì§€ì‹ ê·¸ë˜í”„ êµ¬ì¶• ì¤‘...")

        # ì„¼ì„œ ê´€ê³„ ì •ì˜ (ì‹¤ì œ ì‚°ì—… ì‹œìŠ¤í…œ ê¸°ë°˜)
        sensor_relationships = {
            "D100": {  # ì˜¨ë„ ì„¼ì„œ
                "correlates_with": ["D300"],  # ì „ë ¥ê³¼ ìƒê´€ê´€ê³„
                "affects": ["D101"],  # ì˜¨ë„ê°€ ì••ë ¥ì— ì˜í–¥
                "sensor_type": "temperature",
                "process_group": "thermal_management"
            },
            "D101": {  # ì••ë ¥ ì„¼ì„œ
                "correlates_with": ["D102"],  # ì••ë ¥-ìœ ëŸ‰ ì—°ë™
                "affected_by": ["D100"],  # ì˜¨ë„ì— ì˜í–¥ë°›ìŒ
                "sensor_type": "pressure",
                "process_group": "flow_control"
            },
            "D102": {  # ìœ ëŸ‰ ì„¼ì„œ
                "correlates_with": ["D101"],  # ì••ë ¥ê³¼ ì—°ë™
                "sensor_type": "flow",
                "process_group": "flow_control"
            },
            "D200": {  # ì§„ë™ ì„¼ì„œ ì‹œë¦¬ì¦ˆ
                "correlates_with": ["D300"],  # ì§„ë™-ì „ë ¥ íš¨ìœ¨ì„±
                "sensor_type": "vibration",
                "process_group": "mechanical_health"
            },
            "D201": {
                "correlates_with": ["D200", "D202"],
                "sensor_type": "vibration",
                "process_group": "mechanical_health"
            },
            "D202": {
                "correlates_with": ["D200", "D201"],
                "sensor_type": "vibration",
                "process_group": "mechanical_health"
            },
            "D300": {  # ì „ë ¥ ì„¼ì„œ ì‹œë¦¬ì¦ˆ
                "correlates_with": ["D100", "D200"],  # ì˜¨ë„, ì§„ë™ê³¼ ìƒê´€ê´€ê³„
                "sensor_type": "power",
                "process_group": "efficiency_monitoring"
            },
            "D301": {
                "correlates_with": ["D300", "D302"],
                "sensor_type": "power",
                "process_group": "efficiency_monitoring"
            },
            "D302": {
                "correlates_with": ["D300", "D301"],
                "sensor_type": "power",
                "process_group": "efficiency_monitoring"
            }
        }

        self.knowledge_graph = sensor_relationships
        print(f"ğŸ•¸ï¸ ì§€ì‹ ê·¸ë˜í”„ êµ¬ì¶• ì™„ë£Œ: {len(sensor_relationships)}ê°œ ë…¸ë“œ")

    async def _update_embeddings(self):
        """ë°ì´í„°ë² ì´ìŠ¤ì˜ ëª¨ë“  ì§€ì‹ì— ëŒ€í•œ ì„ë² ë”© ìƒì„±/ì—…ë°ì´íŠ¸"""
        if not self.openai_client:
            print("âš ï¸ OpenAI í´ë¼ì´ì–¸íŠ¸ ì—†ìŒ - ì„ë² ë”© ì—…ë°ì´íŠ¸ ìŠ¤í‚µ")
            return

        print("ğŸ”¢ ì„ë² ë”© ì—…ë°ì´íŠ¸ ì‹œì‘...")

        # 1. knowledge_base í…Œì´ë¸” ì„ë² ë”©
        kb_sql = "SELECT id, content FROM ai_engine.knowledge_base WHERE embedding IS NULL"
        kb_records = await q(kb_sql, ())

        if kb_records:
            for record in kb_records:
                try:
                    embedding = await self._generate_embedding(record['content'])
                    if embedding:
                        update_sql = "UPDATE ai_engine.knowledge_base SET embedding = %s WHERE id = %s"
                        await execute_query(update_sql, (embedding, record['id']))
                        print(f"   âœ… KB ì„ë² ë”© ì—…ë°ì´íŠ¸: ID {record['id']}")
                except Exception as e:
                    print(f"   âŒ KB ì„ë² ë”© ì‹¤íŒ¨: ID {record['id']} - {e}")

        # 2. sensor_knowledge í…Œì´ë¸” ì„ë² ë”©
        sk_sql = "SELECT id, content FROM ai_engine.sensor_knowledge WHERE embedding IS NULL"
        sk_records = await q(sk_sql, ())

        if sk_records:
            for record in sk_records:
                try:
                    embedding = await self._generate_embedding(record['content'])
                    if embedding:
                        update_sql = "UPDATE ai_engine.sensor_knowledge SET embedding = %s WHERE id = %s"
                        await execute_query(update_sql, (embedding, record['id']))
                        print(f"   âœ… SK ì„ë² ë”© ì—…ë°ì´íŠ¸: ID {record['id']}")
                except Exception as e:
                    print(f"   âŒ SK ì„ë² ë”© ì‹¤íŒ¨: ID {record['id']} - {e}")

        print("ğŸ”¢ ì„ë² ë”© ì—…ë°ì´íŠ¸ ì™„ë£Œ")

    async def _generate_embedding(self, text: str) -> Optional[List[float]]:
        """í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì„ë² ë”© ìƒì„±"""
        if not self.openai_client:
            return None

        try:
            response = await self.openai_client.embeddings.create(
                model=self.embedding_model,
                input=text
            )
            return response.data[0].embedding
        except Exception as e:
            print(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    async def vector_search(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """ë²¡í„° ê¸°ë°˜ ì˜ë¯¸ë¡ ì  ê²€ìƒ‰"""
        print(f"\nğŸ” ë²¡í„° ê²€ìƒ‰ ì‹œì‘: query='{query}', top_k={top_k}")

        if not self.openai_client:
            print("âš ï¸ OpenAI í´ë¼ì´ì–¸íŠ¸ ì—†ìŒ - ë²¡í„° ê²€ìƒ‰ ë¶ˆê°€")
            return []

        try:
            # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            query_embedding = await self._generate_embedding(query)
            if not query_embedding:
                return []

            # ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ (PostgreSQL pg_vector)
            search_sql = """
                SELECT
                    'knowledge_base' as source_table,
                    id, content, content_type, metadata,
                    embedding <-> %s as distance,
                    1 - (embedding <-> %s) as similarity
                FROM ai_engine.knowledge_base
                WHERE embedding IS NOT NULL
                UNION ALL
                SELECT
                    'sensor_knowledge' as source_table,
                    id, content, sensor_type as content_type,
                    jsonb_build_object('sensor_tag', sensor_tag) as metadata,
                    embedding <-> %s as distance,
                    1 - (embedding <-> %s) as similarity
                FROM ai_engine.sensor_knowledge
                WHERE embedding IS NOT NULL
                ORDER BY distance ASC
                LIMIT %s
            """

            params = [query_embedding] * 4 + [top_k]
            results = await q(search_sql, params)

            # ìœ ì‚¬ë„ í•„í„°ë§
            filtered_results = [
                r for r in (results or [])
                if r['similarity'] >= self.similarity_threshold
            ]

            print(f"ğŸ” ë²¡í„° ê²€ìƒ‰ ì™„ë£Œ: {len(filtered_results)}ê°œ ê²°ê³¼ (ì„ê³„ê°’: {self.similarity_threshold})")
            return filtered_results

        except Exception as e:
            print(f"âŒ ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    async def graph_expand_search(self, sensor_tags: List[str]) -> List[str]:
        """ê·¸ë˜í”„ ê¸°ë°˜ ì„¼ì„œ í™•ì¥ ê²€ìƒ‰"""
        print(f"\nğŸ•¸ï¸ ê·¸ë˜í”„ í™•ì¥ ê²€ìƒ‰: ì´ˆê¸° íƒœê·¸ {sensor_tags}")

        expanded_tags = set(sensor_tags)

        for tag in sensor_tags:
            if tag in self.knowledge_graph:
                # ì—°ê´€ëœ ì„¼ì„œë“¤ ì¶”ê°€
                correlates = self.knowledge_graph[tag].get('correlates_with', [])
                affected_by = self.knowledge_graph[tag].get('affected_by', [])
                affects = self.knowledge_graph[tag].get('affects', [])

                expanded_tags.update(correlates)
                expanded_tags.update(affected_by)
                expanded_tags.update(affects)

                print(f"   {tag} â†’ ì—°ê´€: {correlates}, ì˜í–¥ë°›ìŒ: {affected_by}, ì˜í–¥ì¤Œ: {affects}")

        result = list(expanded_tags)
        print(f"ğŸ•¸ï¸ í™•ì¥ëœ ì„¼ì„œ íƒœê·¸: {result}")
        return result

    async def hybrid_search(self, query: str, sensor_tags: List[str] = None, top_k: int = 8) -> Dict[str, Any]:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: ë²¡í„° + ê·¸ë˜í”„ + êµ¬ì¡°í™”ëœ ë°ì´í„°"""
        print(f"\nğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œì‘: query='{query}'")

        results = {
            "vector_results": [],
            "graph_expanded_sensors": [],
            "current_sensor_data": [],
            "qc_violations": [],
            "sensor_correlations": []
        }

        # 1. ë²¡í„° ì˜ë¯¸ë¡ ì  ê²€ìƒ‰
        results["vector_results"] = await self.vector_search(query, top_k)
        print(f"   ë²¡í„° ê²€ìƒ‰: {len(results['vector_results'])}ê°œ")

        # 2. ì„¼ì„œ íƒœê·¸ ì¶”ì¶œ ë° ê·¸ë˜í”„ í™•ì¥
        if not sensor_tags:
            sensor_tags = await self._extract_sensor_tags(query)

        if sensor_tags:
            results["graph_expanded_sensors"] = await self.graph_expand_search(sensor_tags)
            print(f"   ê·¸ë˜í”„ í™•ì¥: {len(results['graph_expanded_sensors'])}ê°œ")

            # 3. í™•ì¥ëœ ì„¼ì„œë“¤ì˜ í˜„ì¬ ë°ì´í„°
            for tag in results["graph_expanded_sensors"][:10]:  # ìµœëŒ€ 10ê°œ
                sensor_data = await latest_snapshot(tag)
                if sensor_data:
                    results["current_sensor_data"].extend(sensor_data)
            print(f"   í˜„ì¬ ë°ì´í„°: {len(results['current_sensor_data'])}ê°œ")

            # 4. QC ìœ„ë°˜ ê²€ì‚¬
            results["qc_violations"] = await self._check_qc_violations(results["graph_expanded_sensors"])
            print(f"   QC ìœ„ë°˜: {len(results['qc_violations'])}ê°œ")

            # 5. ì„¼ì„œ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„
            results["sensor_correlations"] = await self._analyze_sensor_correlations(results["graph_expanded_sensors"])
            print(f"   ìƒê´€ê´€ê³„: {len(results['sensor_correlations'])}ê°œ")

        print(f"ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì™„ë£Œ")
        return results

    async def _extract_sensor_tags(self, query: str) -> List[str]:
        """ì¿¼ë¦¬ì—ì„œ ì„¼ì„œ íƒœê·¸ ì¶”ì¶œ"""
        import re

        # D + ìˆ«ì íŒ¨í„´
        pattern = r'D\d{3}'
        matches = re.findall(pattern, query.upper())

        # í‚¤ì›Œë“œ ê¸°ë°˜ ë§¤í•‘
        keyword_mapping = {
            'ì˜¨ë„': ['D100'],
            'ì••ë ¥': ['D101'],
            'ìœ ëŸ‰': ['D102'],
            'ì§„ë™': ['D200', 'D201', 'D202'],
            'ì „ë ¥': ['D300', 'D301', 'D302']
        }

        for keyword, tags in keyword_mapping.items():
            if keyword in query:
                matches.extend(tags)

        return list(set(matches))

    async def _check_qc_violations(self, sensor_tags: List[str]) -> List[Dict[str, Any]]:
        """QC ê·œì¹™ ìœ„ë°˜ ê²€ì‚¬"""
        violations = []

        for tag in sensor_tags:
            try:
                # í˜„ì¬ ì„¼ì„œ ê°’
                current_data = await latest_snapshot(tag)
                if not current_data:
                    continue

                current_value = float(current_data[0].get('value', 0))

                # QC ê·œì¹™
                qc_data = await qc_rules(tag)
                if not qc_data:
                    continue

                qc_rule = qc_data[0]
                min_val = qc_rule.get('min_val')
                max_val = qc_rule.get('max_val')

                # ìœ„ë°˜ ê²€ì‚¬
                if min_val and current_value < float(min_val):
                    violations.append({
                        "sensor_tag": tag,
                        "violation_type": "below_minimum",
                        "current_value": current_value,
                        "threshold": float(min_val),
                        "severity": "critical"
                    })
                elif max_val and current_value > float(max_val):
                    violations.append({
                        "sensor_tag": tag,
                        "violation_type": "above_maximum",
                        "current_value": current_value,
                        "threshold": float(max_val),
                        "severity": "critical"
                    })

            except (ValueError, TypeError, KeyError):
                continue

        return violations

    async def _analyze_sensor_correlations(self, sensor_tags: List[str]) -> List[Dict[str, Any]]:
        """ì„¼ì„œ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„"""
        correlations = []

        for tag in sensor_tags:
            if tag in self.knowledge_graph:
                graph_data = self.knowledge_graph[tag]

                # ê·¸ë˜í”„ì—ì„œ ì •ì˜ëœ ê´€ê³„ë“¤
                for related_tag in graph_data.get('correlates_with', []):
                    if related_tag in sensor_tags:
                        correlations.append({
                            "sensor1": tag,
                            "sensor2": related_tag,
                            "relationship_type": "correlation",
                            "strength": "strong",
                            "process_group": graph_data.get('process_group', 'unknown')
                        })

                for affected_tag in graph_data.get('affects', []):
                    if affected_tag in sensor_tags:
                        correlations.append({
                            "sensor1": tag,
                            "sensor2": affected_tag,
                            "relationship_type": "causal",
                            "direction": "affects",
                            "strength": "medium"
                        })

        return correlations

    async def generate_graph_rag_response(self, query: str) -> str:
        """GraphRAG ê¸°ë°˜ ì‘ë‹µ ìƒì„±"""
        print(f"\nğŸš€ GraphRAG ì‘ë‹µ ìƒì„±: '{query}'")

        try:
            # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ìœ¼ë¡œ ì¢…í•©ì  ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            search_results = await self.hybrid_search(query)

            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context_parts = []

            # ë²¡í„° ê²€ìƒ‰ ê²°ê³¼
            if search_results["vector_results"]:
                context_parts.append("=== ê´€ë ¨ ì§€ì‹ (ë²¡í„° ê²€ìƒ‰) ===")
                for result in search_results["vector_results"][:3]:
                    similarity = result.get('similarity', 0)
                    content = result.get('content', '')
                    context_parts.append(f"[ìœ ì‚¬ë„: {similarity:.2f}] {content}")

            # í˜„ì¬ ì„¼ì„œ ë°ì´í„°
            if search_results["current_sensor_data"]:
                context_parts.append("\n=== í˜„ì¬ ì„¼ì„œ ìƒíƒœ ===")
                for data in search_results["current_sensor_data"][:5]:
                    tag = data.get('tag_name', 'Unknown')
                    value = data.get('value', 'N/A')
                    ts = data.get('ts', 'N/A')
                    context_parts.append(f"- {tag}: {value} (ì‹œê°„: {ts})")

            # QC ìœ„ë°˜ì‚¬í•­
            if search_results["qc_violations"]:
                context_parts.append("\n=== QC ìœ„ë°˜ ì‚¬í•­ ===")
                for violation in search_results["qc_violations"]:
                    tag = violation["sensor_tag"]
                    violation_type = violation["violation_type"]
                    current = violation["current_value"]
                    threshold = violation["threshold"]
                    context_parts.append(f"ğŸš¨ {tag}: {current} ({violation_type}, ì„ê³„ê°’: {threshold})")

            # ì„¼ì„œ ìƒê´€ê´€ê³„
            if search_results["sensor_correlations"]:
                context_parts.append("\n=== ì„¼ì„œ ìƒê´€ê´€ê³„ ===")
                for corr in search_results["sensor_correlations"][:3]:
                    s1, s2 = corr["sensor1"], corr["sensor2"]
                    rel_type = corr["relationship_type"]
                    context_parts.append(f"- {s1} â†” {s2} ({rel_type})")

            context_text = "\n".join(context_parts)

            # OpenAI ì‘ë‹µ ìƒì„±
            if self.openai_client and context_parts:
                system_prompt = """ë‹¹ì‹ ì€ ì‚°ì—…ìš© ì„¼ì„œ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì˜ GraphRAG AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

í•µì‹¬ ì›ì¹™:
1. ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë§Œ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ
2. ë²¡í„° ê²€ìƒ‰, í˜„ì¬ ë°ì´í„°, QC ìœ„ë°˜, ì„¼ì„œ ìƒê´€ê´€ê³„ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„
3. êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì¸ì‚¬ì´íŠ¸ ì œê³µ
4. í™˜ê°(hallucination) ê¸ˆì§€ - í™•ì‹¤í•œ ì •ë³´ë§Œ ì œê³µ

ì‘ë‹µ í˜•ì‹:
- ëª…í™•í•˜ê³  êµ¬ì¡°í™”ëœ ë¶„ì„
- ê´€ë ¨ ì„¼ì„œë“¤ ê°„ì˜ ì—°ê´€ì„± ì„¤ëª…
- í•„ìš”ì‹œ ì¡°ì¹˜ ì‚¬í•­ ì œì•ˆ"""

                user_prompt = f"""ì§ˆë¬¸: {query}

GraphRAG ì»¨í…ìŠ¤íŠ¸:
{context_text}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¢…í•©ì ì´ê³  ì •í™•í•œ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”."""

                response = await self.openai_client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    max_tokens=1000,
                    temperature=0.1  # ë§¤ìš° ë‚®ì€ temperatureë¡œ í™˜ê° ìµœì†Œí™”
                )

                ai_response = response.choices[0].message.content

                # ê²€ìƒ‰ ë¡œê·¸ ê¸°ë¡
                await self._log_search(query, search_results, ai_response)

                return ai_response
            else:
                return "GraphRAG ë¶„ì„ì„ ìœ„í•œ ì¶©ë¶„í•œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        except Exception as e:
            print(f"âŒ GraphRAG ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            return f"GraphRAG ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    async def _log_search(self, query: str, search_results: Dict[str, Any], response: str):
        """ê²€ìƒ‰ ë¡œê·¸ ê¸°ë¡"""
        try:
            # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            query_embedding = await self._generate_embedding(query) if self.openai_client else None

            log_sql = """
                INSERT INTO ai_engine.rag_search_log
                (query_text, query_embedding, search_results, similarity_threshold, created_at)
                VALUES (%s, %s, %s, %s, %s)
            """

            log_data = {
                "vector_count": len(search_results.get("vector_results", [])),
                "sensor_count": len(search_results.get("graph_expanded_sensors", [])),
                "violation_count": len(search_results.get("qc_violations", [])),
                "correlation_count": len(search_results.get("sensor_correlations", [])),
                "response_length": len(response)
            }

            await execute_query(log_sql, (
                query,
                query_embedding,
                json.dumps(log_data),
                self.similarity_threshold,
                datetime.now()
            ))

        except Exception as e:
            print(f"âš ï¸ ê²€ìƒ‰ ë¡œê·¸ ê¸°ë¡ ì‹¤íŒ¨: {e}")


# ì „ì—­ GraphRAG ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤
graph_rag_engine = GraphRAGEngine()


async def initialize_graph_rag_engine():
    """GraphRAG ì—”ì§„ ì´ˆê¸°í™”"""
    await graph_rag_engine.initialize()


async def get_graph_rag_response(query: str) -> str:
    """GraphRAG ê¸°ë°˜ ì‘ë‹µ ìƒì„±"""
    return await graph_rag_engine.generate_graph_rag_response(query)